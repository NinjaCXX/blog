---
layout: page
title: Projects
permalink: /projects/
---


### Domain adaptation
Deep learning and reinforcement learning are key technologies for autonomous driving. One of the challenges they face is to adapt to conditions which differ from those met during training. To improve systems’ performance in such situations, we explore so-called *“domain adaptation”* techniques.

### Annotation efficient learning 
- few-shot learning, self-supervised learning

### 3D dynamic perception
Each sensor delivers information about the 3D world around the vehicle and its temporal evolution. Dectecting, segmenting and tracking important objects (road users, obstacles, street furnitures, etc.) in 3D, as well as forecasting their possible futures, is required for the driving system to plan and act in the safest and most confortable way. This encompasses a wide range of challenging tasks that our research tackles.

### Uncertainty estimation and performance prediction
When the unexpected happens, when the weather badly degrades, when a sensor gets blocked, the embarked perception system should diagnose the situation and react accordingly, *e.g.,* by calling an alternative system or the human driver. With this in mind, we investigate automatic ways to assess the uncertainty of a system and to predict its performance.

### Multi-sensor perception
Automated driving relies first on a diverse range of sensors, like Valeo’s [fish-eye cameras](https://www.valeo.com/en/360-vue/), [LiDARs](https://www.valeo.com/en/valeo-scala/), radars and ultrasonics. Exploiting at best the outputs of each of these sensors at any instant is fundamental to understand the complex environment of the vehicle. To this end, we explore various deep learning approaches where sensors are considered both in isolation and collectively.